{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598392901384",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook scrapes schools level data from schools.org.in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from inscriptis import get_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to retrieve the statewise number of schools and links to data on all schools in the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_contents3(url):\n",
    "    \n",
    "    # open the link to the webpage\n",
    "    # browser.get(url)\n",
    "\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.text, 'html.parser')\n",
    "    table_container = soup.find_all('table')\n",
    "    soup = BeautifulSoup(str(table_container), 'html.parser')\n",
    "\n",
    "    i = 1\n",
    "    j = 1\n",
    "    dic = {}\n",
    "    \n",
    "    for each in soup.find_all('td'):\n",
    "\n",
    "        if(i%3==2):\n",
    "            temp_state = each.text[each.text.find('Schools in')+11:]\n",
    "            temp_link = 'https://schools.org.in/'+each.a.get('href')\n",
    "\n",
    "        elif(i%3==0):\n",
    "            temp_count = each.text\n",
    "            dic[j] = {'state':temp_state, 'link': temp_link, 'number of schools':temp_count}\n",
    "            j+=1\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    # save the dictionary into a dataframe\n",
    "    df_state=pd.DataFrame.from_dict(dic).T\n",
    "    \n",
    "    return df_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to retrieve links to all the districts within each state (to get school data within those districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_contents2(url):\n",
    "    \n",
    "    # open the link to the webpage\n",
    "    #browser.get(url)\n",
    "\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.text, 'html.parser')\n",
    "    table_container = soup.find_all('table')\n",
    "    soup = BeautifulSoup(str(table_container), 'html.parser')\n",
    "\n",
    "    i = 1\n",
    "    j = 1\n",
    "    dic = {}\n",
    "\n",
    "    for each in soup.find_all('td'):\n",
    "        if(i%2==0):\n",
    "            temp_state = each.text[each.text.find('Schools in')+11:]\n",
    "            temp_link = 'https://schools.org.in/'+each.a.get('href')\n",
    "            dic[j] = {'col1':temp_state, 'col2': temp_link}\n",
    "            j+=1\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    # save the dictionary into a dataframe\n",
    "    df_state=pd.DataFrame.from_dict(dic).T\n",
    "    \n",
    "    return df_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to retrive data on all schools within a district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_contents_school(url):\n",
    "    \n",
    "    # open the link to the webpage\n",
    "    #browser.get(url)\n",
    "\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.text, 'html.parser')\n",
    "    table_container = soup.find_all('table')\n",
    "    soup = BeautifulSoup(str(table_container), 'html.parser')\n",
    "\n",
    "    i = 1\n",
    "    j = 1\n",
    "    dic = {}\n",
    "\n",
    "    for each in soup.find_all('td'):\n",
    "\n",
    "        if(i%2==0):\n",
    "            temp_state = each.text\n",
    "            temp_link = 'https://schools.org.in/'+each.a.get('href')\n",
    "            dic[j] = {'col1':temp_state, 'col2': temp_link}\n",
    "            j+=1\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    # save the dictionary into a dataframe\n",
    "    df_state=pd.DataFrame.from_dict(dic).T\n",
    "    return df_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrive school level data from school links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_school_data(url):\n",
    "\n",
    "    vars = ['Instruction Medium', 'Male Teachers', 'Pre Primary Sectin Avilable', 'Board for Class 10<', 'School Type', 'Classes','Female Teacher', 'Pre Primary Teachers','Board for Class 10+2', 'Meal',  'Establishment', 'School Area', 'School Shifted to New Place', 'Head Teachers', 'Head Teacher:', 'Is School Residential', 'Residential Type', 'Total Teachers', 'Contract Teachers', 'Management', 'Village / Town', 'Cluster', 'Block','District','State','UDISE Code','Building','Class Rooms','Boys Toilet', 'Girls Toilet', 'Computer Aided Learning','Electricity', 'Wall','Library', 'Playground','Books in Library','Drinking Water','Ramps for Disable','Computers','Pincode']\n",
    "    # open the link to the webpage\n",
    "    #browser.get(url)\n",
    "\n",
    "    lis = []\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.text, 'html.parser')\n",
    "    table_container = soup.find_all('li', class_='list-group-item')\n",
    "\n",
    "    for each in table_container:\n",
    "\n",
    "        temp_str = str(each)\n",
    "        temp_header = temp_str[temp_str.find('</i>')+4:][:temp_str[temp_str.find('</i>')+4:].find('<b')]\n",
    "        temp_value = temp_str[temp_str.find('<b>')+3:][:temp_str[temp_str.find('<b>')+3:].find('</b')]\n",
    "\n",
    "        if (temp_header==' '):\n",
    "            temp_header = temp_str[temp_str.find('<b>')+3:][:temp_str[temp_str.find('<b>')+3:].find('</b>')]\n",
    "            temp_value = temp_str[temp_str.find('</b>')+4:][:temp_str[temp_str.find('</b>')+4:].find('</li')]\n",
    "\n",
    "        for item in vars:\n",
    "            if (item in temp_header):\n",
    "                if (not((item=='Library') & ('Books in Library' in temp_header))):\n",
    "                    lis.append(temp_value)\n",
    "\n",
    "    txt = get_text(html.text)\n",
    "    lis.append(txt[txt.find('PIN Code')+11:txt.find('PIN Code')+17])\n",
    "    full_d = dict(zip(vars,lis))\n",
    "    \n",
    "    return full_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the above functions to scrape data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://schools.org.in/schools-in-india.html\"\n",
    "\n",
    "school={}\n",
    "j=0\n",
    "flag = 0\n",
    "\n",
    "state_school = get_table_contents3(url)\n",
    "print(state_school)\n",
    "for each in state_school['link']:\n",
    "    print(each)\n",
    "    df1 = get_table_contents2(each)\n",
    "    for item in df1['col2']:\n",
    "\n",
    "        df2 = get_table_contents2(item)\n",
    "        for link in df2['col2']:\n",
    "\n",
    "            df3 = get_table_contents2(link)\n",
    "            for piece in df3['col2']:\n",
    "                \n",
    "                df4 = get_table_contents_school(piece)\n",
    "                if not df4.empty:\n",
    "                    \n",
    "                    for this in df4['col2']:\n",
    "                        temp_state = state_school[state_school['link'] == each ]['state'].item()\n",
    "                        temp_district = df1[df1['col2']==item]['col1'].item()\n",
    "                        temp_block = df2[df2['col2']==link]['col1'].item()\n",
    "                        temp_cluster = df3[df3['col2']==piece]['col1'].item()\n",
    "                        temp_school = df4[df4['col2']==this]['col1'].item()\n",
    "                        temp_dict={'state':temp_state, 'district': temp_district ,'block': temp_block, 'cluster': temp_cluster, 'school': temp_school}\n",
    "                        temp_dict.update(get_school_data(this))\n",
    "                        school[j]=temp_dict\n",
    "                        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dictionary into a dataframe\n",
    "df_data=pd.DataFrame.from_dict(school).T\n",
    "# save the dataframe into an excel file\n",
    "df_data.to_excel('school_detail_data.xlsx',engine='xlsxwriter')"
   ]
  }
 ]
}
